<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <meta property="og:title" content="AttentionHand: Text-driven Controllable Hand Image Generation for 3D Hand Reconstruction in the Wild"/>
  <meta property="og:url" content="https://redorangeyellowy.github.io/AttentionHand/"/>
  <!-- <meta property="og:image" content="static/images/og_tag_header_image.jpg" /> -->
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <title>AttentionHand</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">
  <link rel="icon" href="static/figures/elephant.jpeg">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


<section class="publication-header">
  <div class="hero-body">
    <div class="container is-max-widescreen">
      <!-- <div class="columns is-centered"> -->
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">AttentionHand: Text-driven Controllable Hand Image Generation for 3D Hand Reconstruction in the Wild</h1>
          <h1 class="title is-3">ECCV 2024</h1>
        </div>
    </div>
  </div>   
</section>

<section class="publication-author-block">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
		      <div class="is-size-3 publication-authors">
          </div>
          
          <div class="is-size-3 publication-authors">
            <!-- span class="author-block"> </span> 
            <!-- <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span> -->
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><a href="https://scholar.google.com/citations?user=1OSw79kAAAAJ&hl=ko" target="_blank">Junho Park</a><sup>1,2*</sup>,</span>
            <span class="author-block"><a href="https://scholar.google.com/citations?user=O9QSF7UAAAAJ&hl=ko&oi=ao" target="_blank">Kyeongbo Kong</a><sup>3*</sup>,</span>
            <span class="author-block"><a href="https://scholar.google.com/citations?user=3WYxpuYAAAAJ&hl=ko&oi=ao" target="_blank">Sukju Kang</a><sup>1</sup>,</span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Sogang University,</span>
            <span class="author-block"><sup>2</sup>LG Electronics,</span>
            <span class="author-block"><sup>3</sup>Pusan National University</span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">* : Equal Contribution</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              
              <span class="link-block">
                <a href="https://redorangeyellowy.github.io/AttentionHand/" target="_blank"
                  class="external-link button is-normal is-rounded">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv (comming soon)</span>
                </a>
              </span>

              <!-- Colab Link. -->
              <span class="link-block">
                <a href="https://github.com/redorangeyellowy/AttentionHand" target="_blank"
                class="external-link button is-normal is-rounded">
                <span class="icon">
                  <i class="fab fa-github"></i>
                </span>
                <span>Code</span>
              </a>
              </span>
             <!--span class="link-block">
              <a href=""  target="_blank"
                 class="external-link button is-normal is-rounded">
                <span class="icon">
                    <i class="fas fa-infinity"></i>
                </span>
                <span>Colab</span>
              </a>
             </span -->
            
            <!-- <span class="link-block">
              <a href="https://huggingface.co/spaces/AttendAndExcite/Attend-and-Excite"  target="_blank"
                 class="external-link button is-normal is-rounded">
                <span class="icon">
                    <i class="fas fa-laptop"></i>
                </span>
                <span>Demo</span>
              </a>
             </span> -->
           
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero is-small">
  <!-- <div class="hero-body"> -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <!-- <div id="results-carousel" class="carousel results-carousel"> -->
      <div class="container">
      <div class="item">
      <div class="column is-centered has-text-centered">
        <img src="static/images/pipeline.png" alt="pipeline"/>
      <h2 class="subtitle">
        We propose a novel method, AttentionHand, for text-driven controllable hand image generation.
        (1) In the data preparation phase, we prepare global and local RGB images, global and local hand mesh images, bounding box, and text prompt.
        (2) In the encoding phase, we get global and local latent image embeddings, and text embedding.
        (3) In the conditioning phase, we refine image embeddings through the text attention stage, and obtain the diffusion feature through the visual attention stage.
        (4) In the decoding phase, we generate a new hand image from the diffusion feature.
      </h2>
	  </div>
    </div>
  </div>
 <!--  </div> -->
  </div>
  </div>
 <!--  </div> -->
</section>

<section class="section hero is-light">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <!-- div class="item">
          <p style="margin-bottom: 30px">
        <video poster="" id="tree" autoplay controls muted loop height="100%">
          <source src="static/figures/video.mp4"
          type="video/mp4">
        </video>
        </p>
        </div -->
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Recently, there has been a significant amount of research conducted on 3D hand reconstruction to use various forms of human-computer interaction. 
            However, 3D hand reconstruction in the wild is challenging due to extreme lack of in-the-wild 3D hand datasets. 
            Especially, when hands are in complex pose such as interacting hands, the problems like appearance similarity, self-handed occclusion and depth ambiguity make it more difficult. 
            To overcome these issues, we propose AttentionHand, a novel method for text-driven controllable hand image generation. 
            Since AttentionHand can generate various and numerous in-the-wild hand images well-aligned with 3D hand label, we can acquire a new 3D hand dataset, and can relieve the domain gap between indoor and outdoor scenes. 
            Our method needs easy-to-use four modalities (i.e, an RGB image, a hand mesh image from 3D label, a bounding box, and a text prompt). 
            These modalities are embedded into the latent space by the encoding phase. 
            Then, through the text attention stage, hand-related tokens from the given text prompt are attended to highlight hand-related regions of the latent embedding. 
            After the highlighted embedding is fed to the visual attention stage, hand-related regions in the embedding are attended by conditioning global and local hand mesh images with the diffusion-based pipeline. 
            In the decoding phase, the final feature is decoded to new hand images, which are well-aligned with the given hand mesh image and text prompt. 
            As a result, AttentionHand achieved state-of-the-art among text-to-hand image generation models, and the performance of 3D hand mesh reconstruction was improved by additionally training with hand images generated by AttentionHand.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title has-text-centered">Video</h2>
      <center>
        <iframe width="630" height="354" src="https://www.youtube.com/embed/9EWs2IX4cus" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
      </center>
    </div>
  </div>
</section>

<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title has-text-centered">Examples of Text-to-Image Generation with Attend-and-Excite</h2>
      <div id="results-carousel" class="carousel results-carousel">
	  <div class="column is-centered has-text-centered">
        <img src="static/figures/grizzly.jpg" alt="cars peace" width="800px"/>
      </div>
	  <div class="column is-centered has-text-centered">
        <img src="static/figures/elephant.jpg" alt="cars peace" width="800px"/>
      </div>
	  <div class="column is-centered has-text-centered">
        <img src="static/figures/dog_mouse.jpg" alt="cars peace" width="800px"/>
      </div>
      <div class="column is-centered has-text-centered">
        <img src="static/figures/picasso.jpg " alt="cars peace"  width="800px"/>
	   </div>
	   <div class="column is-centered has-text-centered">
        <img src="static/figures/lion_glasses.jpg" alt="cars peace" width="800px"/>
      </div>
	   <div class="column is-centered has-text-centered">
        <img src="static/figures/cake_tulips.jpg" alt="cars peace" width="800px"/>
      </div>
	  <div class="column is-centered has-text-centered">
        <img src="static/figures/swan_kitchen.jpg" alt="cars peace" width="800px"/>
      </div>
	   <div class="column is-centered has-text-centered">
        <img src="static/figures/cat_dog.jpg" alt="cars peace" width="800px"/>
      </div>
	  <div class="column is-centered has-text-centered">
        <img src="static/figures/mouse_car.jpg" alt="cars peace" width="800px"/>
      </div>
	  <div class="column is-centered has-text-centered">
        <img src="static/figures/dolphins.jpg" alt="cars peace" width="800px"/>
      </div>
  </div>
</div>
</div>
</section>







<section class="section hero is-light">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">How does it work?</h2>
        <div class="content has-text-justified">
        </div>
		<div class="column is-centered has-text-centered">
        <img src="static/figures/semantic_issues.png" alt="cars peace" width="700px"/>
		</div>
		<p class="content has-text-justified">
            We observe two semantic issues of existing text-to-image models. 
			First, catastrophic neglect, where one or more subjects is not generated by the model, such as the cat in the example on the left. 
			Second, incorrect attribute bindings, where an attribute such as a color is incorrectly matched to a subject. In the example on the right, the bench is incorrectly colored yellow instead of brown. 
  
          </p>
        <div class="column is-centered has-text-centered">
        <img src="static/figures/overview.png" alt="cars peace" width="700px"/>
      </div>
        <div class="content has-text-justified">
          <p>
			Text conditioning in Stable Diffusion is performed via the cross-attention mechanism. As illustrated on the second row, the attention matrix can be reshaped to obtain a spatial map per text token. Intuitively, for a token to be manifested in the generated image, there should be at least one patch in its map with a high activation value. Attend-and-Excite embodies this intuition by shifting the latent such that it is encouraged to attend to all subject tokens in the text.
			<br>
            Given a prompt (e.g., "A lion with a crown"), we extract the subject tokens (lion, crown), and their corresponding attention maps (second row). We apply a Gaussian kernel on each attention map to obtain smoothed attention maps that consider the neighboring patches. Our optimization enhances the maximal activation of the most neglected token at timestep t and updates the latent code accordingly (row 3). In other words, we shift the latent in the current timestep such that the attention maps for the updated latents attend to the most neglected token. 
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section> 

<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <!-- <p style="margin-top: 30px; margin-bottom: 30px"> -->
      <h2 class="title has-text-centered">Using Cross-Attention as Explanation</h2>
      <!-- </p> -->
      
      <div id="results-carousel" class="carousel results-carousel">
        <div class="column is-centered has-text-centered">
        <img src="static/figures/expl_cat_frog.png" width="400" class="is-centered"/>
        </div>
        <div class="column is-centered has-text-centered">
        <img src="static/figures/expl_elephant_crown.png" width="400" class="is-centered"/>
        </div>
		<div class="column is-centered has-text-centered">
        <img src="static/figures/expl_turtle_bowl.png" width="400" class="is-centered"/>
        </div>
		<div class="column is-centered has-text-centered">
        <img src="static/figures/expl_backpack_glasses.png" width="400" class="is-centered"/>
        </div>
    </div>
  </div>

</section>


<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <!-- Paper poster -->

      <h2 class="title has-text-centered">Uncurated Results</h2>
      <p style="margin-top: 30px; margin-bottom: 30px">
      <!-- <div class="column is-four-fifths"> -->
          <div class="column is-centered has-text-centered">
        <img src="static/figures/uncurated.jpg" alt="cars peace" width="800px"/>
      </div>
       </p>
		<h2 class="subtitle is-centered has-text-centered">
          Uncurated results with the same 8 random seeds comparing Stable Diffusion and Attend-and-Excite.
        </h2>
      </div>
    </div>

  </section> 

<footer class="footer">
  <div class="columns is-centered">
    <div class="column is-8">
      <div class="content">
        <p>
          This website is licensed under a <a rel="license"
          href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
        Commons Attribution-ShareAlike 4.0 International License</a>.
      </p>
      <p>
        Website source code based on the <a href="https://nerfies.github.io/"> Nerfies</a> project page. If you want to reuse their <a
        href="https://github.com/nerfies/nerfies.github.io">source code</a>, please credit them appropriately.
      </p>
    </div>
  </div>
</div>
</div>
</footer>


  <script type="text/javascript">
    var sc_project=12351448; 
    var sc_invisible=1; 
    var sc_security="c676de4f"; 
  </script>
  <script type="text/javascript"
  src="https://www.statcounter.com/counter/counter.js"
  async></script>
  <noscript><div class="statcounter"><a title="Web Analytics"
    href="https://statcounter.com/" target="_blank"><img
    class="statcounter"
    src="https://c.statcounter.com/12351448/0/c676de4f/1/"
    alt="Web Analytics"></a></div></noscript>
    <!-- End of Statcounter Code -->

  </body>
  </html>